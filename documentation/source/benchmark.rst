Benchmarking Coreset Algorithms
==============================

In this benchmark, we test the performance of four different coreset algorithms:
**Kernel Herding**, **Stein Thinning**, **Random Sampling**, and **RP Cholesky**. Each of these algorithms is evaluated across four different tests, providing a comprehensive comparison of their performance and applicability to different datasets.

Test 1: Benchmarking Coreset Algorithms on the MNIST Dataset
----------------------------------------------------------

The first test evaluates the performance of the coreset algorithms on the **MNIST dataset** using a simple neural network classifier. The process follows these steps:

1. **Dataset**: The MNIST dataset consists of 60,000 training images and 10,000 test images. Each image is a 28x28 pixel gray-scale image of a handwritten digit.

2. **Model**: A Multi-Layer Perceptron (MLP) neural network is used for classification, consisting of a single hidden layer with 64 nodes. The images are flattened into vectors to be input into the neural network.

3. **Dimensionality Reduction**: To speed up the computation and reduce dimensionality, we apply **UMAP** to project the 28x28 images into 16 components before applying any coreset algorithm.

4. **Coreset Generation**: Coresets of various sizes are generated using the different coreset algorithms:
   - For **Kernel Herding** and **Stein Thinning**, **MapReduce** is employed to handle the large-scale data efficiently.

5. **Training**: The model is trained using the selected coresets, and the accuracy is measured on the test set of 10,000 images.

6. **Evaluation**: Due to the inherent randomness in both the coreset algorithms and the training process, the experiment is repeated 5 times with different random seeds to get reliable results.

7. **Results Visualization**: The results are stored and visualized using the script `coreset.benchmark.mnist_benchmark_visualiser.py`, which plots error bars (min, max, mean) for accuracy across different coreset sizes.

8. **System**: The benchmark is run on an **Amazon g4dn.12 x large instance** with 4 NVIDIA T4 Tensor Core GPUs, 48 virtual CPUs, and 192 GiB of memory.

**Expected Output**:
- Plots showing the accuracy (with error bars) for each coreset size and algorithm. Below is an example placeholder for such a plot:

  .. image:: ../_images/mnist_benchmark_accuracy.png
     :alt: Benchmark Results for MNIST Coreset Algorithms

  .. image:: ../_images/mnist_benchmark_time_taken.png
   :alt: Time Taken Benchmark Results for MNIST Coreset Algorithms

---

Test 2: Benchmarking Coreset Algorithms on a Synthetic Dataset
-------------------------------------------------------------

In this second test, we evaluate the performance of the coreset algorithms on a **synthetic dataset**. The dataset consists of 1,000 two-dimensional points, generated using `sklearn.datasets.make_blobs`. The process follows these steps:

1. **Dataset**: A synthetic dataset of 1,000 points is generated, which can be used to test the quality of coreset algorithms in a low-dimensional setting.

2. **Coreset Generation**: Coresets of different sizes (10, 50, 100, and 200 points) are generated using each of the coreset algorithms.

3. **Evaluation Metrics**: Two metrics are used to evaluate the quality of the generated coresets:
   - **Maximum Mean Discrepancy (MMD)**
   - **Kernel Stein Discrepancy (KSD)**

4. **Optimization**: We optimize the weights for the coresets to minimize the MMD score and recompute both MMD and KSD metrics.

5. **Time Measurement**: The time taken for each step of the benchmarking process is measured and reported.

**Expected Output**:
- MMD and KSD metric values for each coreset size and algorithm.
- Time measurements for each part of the benchmarking process.
- Plots showing the performance of each coreset algorithm. Here is an example placeholder plot:

  .. image:: _images/david_coreset.png
     :alt: Benchmark Results for Synthetic Dataset
     :width: 600px

---

Test 3: Benchmarking Coreset Algorithms on Pixel Data from an Image
-------------------------------------------------------------------

This test evaluates the performance of coreset algorithms on pixel data extracted from an input image. The process follows these steps:

1. **Input Image**: An input image is loaded and downsampled to reduce its resolution (the downsampling factor of 1 corresponds to no downsampling).

2. **Image Preprocessing**: The image is converted to gray-scale, and pixel locations and values are extracted for use in the coreset algorithms.

3. **Coreset Generation**: Coresets are generated using each of the coreset algorithms.

4. **Visualization**: The original image is plotted alongside the coresets generated by each algorithm. This visual comparison helps assess how well each algorithm represents the original image.

5. **Saving Output**: The resulting plots are saved as PNG files. As a placeholder, here is an example image of a coreset visualization:

  .. image:: _images/david_coreset.png
     :alt: Coreset Visualization on Image
     :width: 600px

6. **Time Measurement**: Each coreset algorithm is timed, and the time taken for each step is reported.

**Expected Output**:
- PNG files showing the original image and the corresponding coresets generated by each algorithm.

---

Test 4: Benchmarking Coreset Algorithms on Frame Data from a GIF
----------------------------------------------------------------

The fourth and final test evaluates the performance of coreset algorithms on data extracted from an input **GIF**. This test involves the following steps:

1. **Input GIF**: An input GIF is loaded, and its frames are preprocessed.

2. **Dimensionality Reduction**: The frame data is reshaped, and **PCA** (Principal Component Analysis) is applied to reduce the dimensionality.

3. **Coreset Generation**: Coresets are generated using each of the coreset algorithms, and the selected frames are saved as new GIFs.

4. **Time Measurement**: The time taken to generate each coreset is recorded and reported.

**Expected Output**:
- GIF files showing the selected frames for each coreset algorithm. Below is an example placeholder GIF:

  .. image:: ../_images/KernelHerding_coreset.gif
     :alt: Coreset Visualization on GIF Frames


  .. image:: ../../examples/pounce/pounce_coreset.gif
     :alt: Coreset Visualization on GIF Frames

---

Conclusion
----------

In this benchmark, we evaluated four different coreset algorithms on various datasets and tasks, ranging from image classification to synthetic datasets and pixel/frame data processing. The results and visualizations generated from this benchmarking process will help to compare the efficiency and effectiveness of each algorithm across different applications.
